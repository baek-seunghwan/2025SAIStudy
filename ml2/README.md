# [2025 데이스쿨 ML2] 자동차 보험 사기 탐지 – 인터뷰 노트

---

## 1. 새로운 기술을 학습하고 적용한 경험

- 해커톤 기간이 짧고 데이터 규모가 컸기 때문에, 빠른 실험과 병렬 처리가 가능한 환경이 필요했습니다.  
  Python 기반의 `pandas`, `NumPy`, `scikit-learn`을 사용해 데이터 정제와 모델 평가를 일관된 흐름으로 구축했습니다.  
- 범주형 변수가 많은 보험 데이터 특성상, 범주 처리에 강한 **CatBoost**와 **LightGBM**을 병행 실험했습니다.  
  CatBoost는 별도의 One-Hot Encoding 없이 좋은 성능을 보였고, LightGBM은 빠른 학습 속도를 제공해  
  두 모델을 앙상블해 최종 성능을 높였습니다.  
- 데이터 조인과 로그 분석에 시간이 많이 소요되어, **PySpark**를 도입해 처리 속도를 약 4배 단축했습니다.  
  추가로 **Hadoop HDFS**를 활용해 실험 로그와 피처 중요도 파일을 중앙 저장소로 관리했습니다.  
- 여러 스크립트를 수동 실행하며 생기던 실수를 방지하기 위해 **Airflow**로  
  `데이터 적재 → 전처리 → 모델 학습 → 제출 파일 생성` 전 과정을 자동화했습니다.  
  이 자동화로 실험 시간이 약 3시간에서 45분으로 줄었고, 매 실험의 재현성과 효율이 개선되었습니다.

---

## 2. 본인의 역할과 결과가 드러나는 프로젝트 사례

| 구분 | 구체적인 실행 내용 | 결과 및 성과 |
| --- | --- | --- |
| 팀장 백승환 / 파이프라인 설계 | Airflow 기반 데이터 파이프라인 설계, Spark 전처리 코드 작성, HDFS 로그 관리 | 실험 자동화 구축 → 재실행 시간 30분 → 5분 |
| 피처 엔지니어링 | 보험 도메인 분석을 바탕으로 파생 피처 20여 개 생성 (`claim_to_income_ratio`, `vehicle_age_gap` 등) | CatBoost Validation F1 Score 0.22 → 0.36 (+63%) |
| 모델 평가 및 개선 | Stratified K-Fold, Threshold 튜닝, Class Weight 조정 | 공개 리더보드 F1 0.58대 → 최종 장려상 수상 |
| 대회 종료 후 코드 재정비 | 기존 파이프라인과 피처 구조를 수정해 추가 실험 진행 | 공개 리더보드 기준 F1 0.60326 (2위 기록) |

---

## 3. 데이터 구조를 깊이 이해하려 노력한 경험

- 보험 청구 데이터는 차량 정보, 운전자 이력, 사고 내역, 보상금 등 100여 개 컬럼으로 구성되어 있었습니다.  
  단순 통계가 아닌 **도메인 기반 상관 분석**을 위해 실제 보험 문헌을 참고하며 변수 간 관계를 정리했습니다.  
- 사고 책임 비율(`liab_prct`)과 예상 보상금(`claim_est_payout`)이 함께 증가할 때 사기 가능성이 높아지는 패턴을 발견했습니다.  
  이를 바탕으로 `claim_to_income_ratio`, `liab_payout_gap` 등 새로운 파생 피처를 설계했습니다.  
- 이상치 처리를 위해 IQR 기반 필터링과 로그 변환을 적용했고,  
  범주형 변수에는 Target Encoding과 CatBoost의 Ordered Encoding을 병행해 정보 손실을 최소화했습니다.  
- 피처 중요도를 SHAP 값으로 시각화해 모델의 의사결정 과정을 해석 가능하게 만들었으며,  
  최종적으로 재현율(Recall)이 0.41에서 0.58로 향상되었습니다.
